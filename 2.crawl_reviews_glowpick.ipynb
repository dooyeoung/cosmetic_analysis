{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep\n",
    "from time import time\n",
    "import math\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class review:\n",
    "    def __init__(self, pn, name, age, ftype, sex, point, comment):\n",
    "        self.pn = pn\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.ftype = ftype\n",
    "        self.sex = sex\n",
    "        self.point = point\n",
    "        self.comment = comment\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{},{},{},{},{},{}'.format(self.pn, self.name, self.age, self.ftype, self.point, self.comment)\n",
    "\n",
    "class ingredient():\n",
    "    def __init__(self, pn, kname, ename, exp, level, degree):\n",
    "        self.pn = pn\n",
    "        self.kname = kname\n",
    "        self.ename = ename\n",
    "        self.exp = exp\n",
    "        self.level = level\n",
    "        self.degree = degree\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '{},{},{},{},{},{}'.format(self.pn, self.kname, self.ename, self.exp, self.level, self.degree)\n",
    "\n",
    "def crawl_ingredient(pn):\n",
    "    # 화장품성분  \n",
    "    \n",
    "    info = driver.find_elements_by_xpath('//*[@id=\"gp-product-detail\"]/div/ul[1]/li[2]/div/section[2]/div/div/button')\n",
    "    if len(info)>0:\n",
    "        for _ in range(20):\n",
    "            try:\n",
    "                info[0].click()\n",
    "                break\n",
    "            except:\n",
    "                sleep(0.5)\n",
    "                info = driver.find_elements_by_xpath('//*[@id=\"gp-product-detail\"]/div/ul[1]/li[2]/div/section[2]/div/div/button')\n",
    "                pass\n",
    "            \n",
    "    else:\n",
    "        return []\n",
    "     \n",
    "    st = time()\n",
    "    while(True):        \n",
    "        measures = driver.find_elements_by_css_selector('section.side-info.ingredient div.list-ingredient')\n",
    "        if len(measures)>0:\n",
    "            measures = measures[0]\n",
    "            measures = measures.find_elements_by_class_name('list')\n",
    "            break\n",
    "        if time() - st > 3:\n",
    "            measures = []\n",
    "            break\n",
    "     \n",
    "    ings =[]\n",
    "    for m in measures:\n",
    "        soup = BeautifulSoup(m.get_attribute('innerHTML'), 'lxml')\n",
    "        icon = soup.select_one('div.list-item > span')\n",
    "        icontxt = icon.text\n",
    "        icon = icon['class'][2]\n",
    "\n",
    "        names = soup.select('div.list-item div.txt p')\n",
    "        narr = names[0].text.split('\\n')\n",
    "        n1 = narr[0].strip()\n",
    "        n2 = narr[1].strip()\n",
    "        n3 = names[1].text.strip() \n",
    "        #print(icontxt, icon)\n",
    "        ing = ingredient(pn, n1, n2, n3, icontxt, icon)\n",
    "        ings.append(ing)\n",
    "    return ings\n",
    "\n",
    "def crawl_reviews(pn):\n",
    "    driver.get('https://www.glowpick.com/product/{}'.format(pn))     \n",
    "    uf = 'https://www.glowpick.com/product/{}?rating={}&order={}'  \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 리뷰 개수 체크용\n",
    "    count = '#gp-product-detail > div > ul.section-list-wrap.side-bottom > li.section-list-score.side-right > section > div > div.side-right > ul > li:nth-child({}) > div > p'\n",
    "    creviews = [] \n",
    "    \n",
    "    # 상품설명\n",
    "    exp = driver.find_element_by_css_selector('#gp-product-detail > div > ul.section-list-wrap.side-bottom > li.section-list-pdt.side-left > section > div > ul > li.desc > p').text\n",
    "\n",
    "    # 상품 키워드\n",
    "    tag = driver.find_element_by_css_selector('#gp-product-detail > div > ul.section-list-wrap.side-bottom > li.section-list-pdt.side-left > section > div > ul > li.desc > ul').text\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    pdic = {'gpa-best': 5, 'gpa-good': 4, 'gpa-soso': 3, 'gpa-bad': 2, 'gpa-worst': 1}\n",
    "\n",
    "    cnts = driver.find_element_by_xpath('//*[@id=\"gp-product-detail\"]/div/ul[1]/li[2]/div/section[1]/div[1]/div/span[3]').text\n",
    "    cnts = cnts.replace('(','').replace(')','').replace(',','')\n",
    "    cnts = int(cnts) \n",
    "    if cnts != 0:\n",
    "        for fn1, cidx in zip(range(5, 0, -1), range(1, 6)):  \n",
    "            for idx, fn2 in enumerate(['create_date_asc','create_date_desc','like_desc','like_asc']):\n",
    "                url = uf.format(pn, fn1, fn2)\n",
    "                driver.get(url)\n",
    "                #sleep(0.5)\n",
    "\n",
    "                # 앱으로보기 링크 있을경우 끄기\n",
    "                banners = driver.find_elements_by_xpath('//*[@id=\"top-downloadbanner\"]/button')\n",
    "                if len(banners)>0:\n",
    "                    banners[0].click()\n",
    "    \n",
    "    \n",
    "                cnt = driver.find_element_by_css_selector(count.format(cidx)).text\n",
    "                cnt = int(cnt) \n",
    "                if cnt == 0:\n",
    "                    break\n",
    "                loop = min(math.ceil(cnt/20), 5)\n",
    "                noloop1 = noloop2 = False\n",
    "                if cnt <= 100: noloop1 = True\n",
    "                if cnt <= 200: noloop2 = True\n",
    "                    \n",
    "                    \n",
    "                nor = driver.find_elements_by_xpath('//*[@id=\"gp-product-detail\"]/div/ul[2]/li[5]/div/button')\n",
    "                if len(nor)==0:\n",
    "                    st = time()\n",
    "                    # 리뷰 리스트가 없으면 찾을때까지 대기\n",
    "                    while(True):\n",
    "                        rlist = driver.find_elements_by_class_name('review-list-wrap')\n",
    "                        if len(rlist)>0:\n",
    "                            if (rlist[0].text != ''):\n",
    "                                body = driver.find_element_by_css_selector('body')\n",
    "                                body.click()\n",
    "                                break\n",
    "                        else:\n",
    "                            driver.get(url)\n",
    "                            sleep(0.5)\n",
    "\n",
    "                        if time() - st > 30:\n",
    "                            errors.append([pn, fn1, fn2])\n",
    "                            break\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "  \n",
    "                # 최대 100개, 스크롤 해야 로드하기 때문에 end키 조작으로 리뷰 불러오기\n",
    "                st = time()\n",
    "                while(True):\n",
    "                    try:\n",
    "                        body.send_keys(Keys.END) \n",
    "                        reviews = driver.find_elements_by_css_selector('ul.review-list-wrap li div.list-item') \n",
    "\n",
    "                        if time() - st > 3:\n",
    "                            body.send_keys(Keys.PAGE_UP)\n",
    "                            sleep(0.1) \n",
    "                            body.send_keys(Keys.END)\n",
    "                            st = time()\n",
    "\n",
    "                        if len(reviews) > (loop-1) * 20:\n",
    "                            break\n",
    "\n",
    "                    except Exception as e:\n",
    "                        body = driver.find_element_by_css_selector('body')\n",
    "                        body.click()\n",
    "\n",
    "\n",
    "                #print(len(reviews))\n",
    "                # 리뷰 크롤링\n",
    "                # beautifulsoup이 좀더 빠르다\n",
    "                for r in reviews:\n",
    "                    soup = BeautifulSoup(r.get_attribute('innerHTML'), 'lxml')\n",
    "                    user = soup.select_one('.user .user-info')\n",
    "                    name = user.select_one('.name').text\n",
    "                    agetype = user.select_one('.info .txt')\n",
    "                    arr = agetype.text.split('·')\n",
    "                    age = int(arr[0].replace('세',''))\n",
    "                    ftype = arr[1] \n",
    "                    sex = agetype.select_one('span')['class']\n",
    "                    point = user.select_one('.info .label span')['class'][1]\n",
    "                    point = pdic[point]\n",
    "\n",
    "                    comment = soup.select_one('.review').text\n",
    "\n",
    "                    cr = review(pn, name, age, ftype, sex, point, comment)\n",
    "                    creviews.append(cr)\n",
    "\n",
    "                if noloop1: break \n",
    "                if noloop2 & (idx >= 1):break\n",
    "\n",
    "        #rank = driver.find_element_by_css_selector('#gp-product-detail > div > ul.section-list-wrap.side-top > li.section-list-img.side-left > div > section > ul > li > span').text\n",
    "        #print(rank) \n",
    "     \n",
    "    ing = crawl_ingredient(pn)\n",
    "    \n",
    "    return exp, tag, creviews, ing, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cate</th>\n",
       "      <th>cid</th>\n",
       "      <th>rank</th>\n",
       "      <th>change</th>\n",
       "      <th>diff</th>\n",
       "      <th>pn</th>\n",
       "      <th>company</th>\n",
       "      <th>name</th>\n",
       "      <th>volume</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미스트</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95080</td>\n",
       "      <td>홀리카홀리카</td>\n",
       "      <td>굳세라 수퍼 세라마이드 미스트</td>\n",
       "      <td>120ml</td>\n",
       "      <td>15,000원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>미스트</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27484</td>\n",
       "      <td>한율</td>\n",
       "      <td>어린쑥 수분 진정수</td>\n",
       "      <td>150ml</td>\n",
       "      <td>25,000원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>미스트</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51533</td>\n",
       "      <td>CNP(차앤박)</td>\n",
       "      <td>프로폴리스 앰플 미스트</td>\n",
       "      <td>100ml</td>\n",
       "      <td>15,000원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>미스트</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58165</td>\n",
       "      <td>비어썸(Beausome)</td>\n",
       "      <td>오우썸 하이드레이팅 오가닉 더블미스트</td>\n",
       "      <td>120ml</td>\n",
       "      <td>22,000원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미스트</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99864</td>\n",
       "      <td>보타닉힐 보</td>\n",
       "      <td>더마 인텐시브 판테놀 크림 미스트</td>\n",
       "      <td>120ml</td>\n",
       "      <td>15,000원</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cate  cid rank change  diff     pn        company                  name  \\\n",
       "0  미스트    1    1    NaN   NaN  95080         홀리카홀리카      굳세라 수퍼 세라마이드 미스트   \n",
       "1  미스트    1    2    NaN   NaN  27484             한율            어린쑥 수분 진정수   \n",
       "2  미스트    1    3    NaN   NaN  51533       CNP(차앤박)          프로폴리스 앰플 미스트   \n",
       "3  미스트    1    4    NaN   NaN  58165  비어썸(Beausome)  오우썸 하이드레이팅 오가닉 더블미스트   \n",
       "4  미스트    1    5    NaN   NaN  99864         보타닉힐 보    더마 인텐시브 판테놀 크림 미스트   \n",
       "\n",
       "  volume    price  \n",
       "0  120ml  15,000원  \n",
       "1  150ml  25,000원  \n",
       "2  100ml  15,000원  \n",
       "3  120ml  22,000원  \n",
       "4  120ml  15,000원  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/rank.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f549a6db6a8141729e5b37bb35ad9e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reviw_res = []\n",
    "for idx in tqdm_notebook(df[df['cate']=='스킨'].index):\n",
    "    pn = df.loc[idx, 'pn']\n",
    "    res = crawl_reviews(pn)\n",
    "    reviw_res.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 200, 100, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_skin), len(data_lotion), len(data_cream), len(data_faceoil), len(data_mist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/skin.plk', 'rb') as f:\n",
    "    data_skin = pickle.load(f)\n",
    "    \n",
    "with open('data/lotion.plk', 'rb') as f:\n",
    "    data_lotion = pickle.load(f)\n",
    "    \n",
    "with open('data/mist.plk', 'rb') as f:\n",
    "    data_mist = pickle.load(f)\n",
    "\n",
    "with open('data/cream.plk', 'rb') as f:\n",
    "    data_cream = pickle.load(f)\n",
    "\n",
    "with open('data/faceoil.plk', 'rb') as f:\n",
    "    data_faceoil = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "rres = []\n",
    "for data in [data_skin, data_lotion, data_mist, data_cream, data_faceoil]:\n",
    "    for dt in data:\n",
    "        rs = dt[2]\n",
    "        for r in rs:\n",
    "            rres.append([r.pn, r.name, r.age, r.ftype, r.point, r.comment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_review = pd.DataFrame(rres, columns=['pn','author','age','ftype','point','ment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_review.to_csv('data/total_review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "rres = []\n",
    "for data in [data_skin, data_lotion, data_mist, data_cream, data_faceoil]:\n",
    "    for dt in data:\n",
    "        rs = dt[3]\n",
    "        for r in rs:\n",
    "            rres.append([r.pn, r.kname, r.ename, r.exp, r.level, r.degree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ing = pd.DataFrame(rres, columns=['pn','kname','ename','exp','level','degree'])\n",
    "total_ing.to_csv('data/total_ing.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres = []\n",
    "for cate, data in zip(['스킨','로션','미스트','크림','페이스오일'], [data_skin, data_lotion, data_mist, data_cream, data_faceoil]):\n",
    "    df_skin1 = df[df['cate']==cate].reset_index(drop=True)\n",
    "    df_skin2 = pd.DataFrame(data, columns=['exp','tags','r','i','e'])\n",
    "    df_skinm = pd.concat([df_skin1, df_skin2], axis=1)\n",
    "    df_skinm = df_skinm.drop(columns=['r','i','e'])\n",
    "    dfres.append(df_skinm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat(dfres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_csv('data/total_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class review:\n",
    "#     def __init__(self, pn, name, age, ftype, sex, point, comment):\n",
    "#         self.pn = pn\n",
    "#         self.name = name\n",
    "#         self.age = age\n",
    "#         self.ftype = ftype\n",
    "#         self.sex = sex\n",
    "#         self.point = point\n",
    "#         self.comment = comment\n",
    "    \n",
    "#     def __repr__(self):\n",
    "#         return '{},{},{},{},{},{}'.format(self.pn, self.name, self.age, self.ftype, self.point, self.comment)\n",
    "\n",
    "# class ingredient():\n",
    "#     def __init__(self, pn, kname, ename, exp, level, degree):\n",
    "#         self.pn = pn\n",
    "#         self.kname = kname\n",
    "#         self.ename = ename\n",
    "#         self.exp = exp\n",
    "#         self.level = level\n",
    "#         self.degree = degree\n",
    "        \n",
    "#     def __repr__(self):\n",
    "#         return '{},{},{},{},{},{}'.format(self.pn, self.kname, self.ename, self.exp, self.level, self.degree)\n",
    "\n",
    "# def crawl_ingredient(pn):\n",
    "#     # 화장품성분  \n",
    "#     for n in range(5):\n",
    "#         info = driver.find_elements_by_css_selector('section.section-list-item.ingredient.moreinfo div button')\n",
    "#         sleep(1)\n",
    "#         if len(info)>0:\n",
    "#             info[0].click()\n",
    "#             break\n",
    "            \n",
    "#     if len(info) == 0:\n",
    "#         return []\n",
    "            \n",
    "#     measures = driver.find_element_by_css_selector('section.side-info.ingredient div.list-ingredient')\n",
    "#     measures = measures.find_elements_by_class_name('list')\n",
    "\n",
    "#     ings =[]\n",
    "#     for m in measures:\n",
    "#         soup = BeautifulSoup(m.get_attribute('innerHTML'), 'lxml')\n",
    "#         icon = soup.select_one('div.list-item > span')\n",
    "#         icontxt = icon.text\n",
    "#         icon = icon['class'][2]\n",
    "\n",
    "#         names = soup.select('div.list-item div.txt p')\n",
    "#         narr = names[0].text.split('\\n')\n",
    "#         n1 = narr[0].strip()\n",
    "#         n2 = narr[1].strip()\n",
    "#         n3 = names[1].text.strip() \n",
    "#         #print(icontxt, icon)\n",
    "#         ing = ingredient(pn, n1, n2, n3, icontxt, icon)\n",
    "#         ings.append(ing)\n",
    "#     return ings\n",
    "\n",
    "# def crawl_reviews(pn):\n",
    "#     driver.get('https://www.glowpick.com/product/{}'.format(pn))    \n",
    "#     sleep(0.5)\n",
    "    \n",
    "#     uf = 'https://www.glowpick.com/product/{}?rating={}&order={}'\n",
    "    \n",
    "#     # 리뷰 개수 파악\n",
    "#     count = '#gp-product-detail > div > ul.section-list-wrap.side-bottom > li.section-list-score.side-right > section > div > div.side-right > ul > li > div > p'\n",
    "#     cnts = [int(cnt.text) for cnt in driver.find_elements_by_css_selector(count)]\n",
    "    \n",
    "#     # 리뷰 개수 체크용\n",
    "#     count = '#gp-product-detail > div > ul.section-list-wrap.side-bottom > li.section-list-score.side-right > section > div > div.side-right > ul > li:nth-child({}) > div > p'\n",
    "#     creviews = [] \n",
    "    \n",
    "#     # 상품설명\n",
    "#     exp = driver.find_element_by_css_selector('#gp-product-detail > div > ul.section-list-wrap.side-bottom > li.section-list-pdt.side-left > section > div > ul > li.desc > p').text\n",
    "\n",
    "#     # 상품 키워드\n",
    "#     tag = driver.find_element_by_css_selector('#gp-product-detail > div > ul.section-list-wrap.side-bottom > li.section-list-pdt.side-left > section > div > ul > li.desc > ul').text\n",
    "    \n",
    "#     errors = []\n",
    "    \n",
    "#     pdic = {'gpa-best': 5, 'gpa-good': 4, 'gpa-soso': 3, 'gpa-bad': 2, 'gpa-worst': 1}\n",
    "#     #print(cnts)\n",
    "#     for cnt, fn1, cidx in zip(cnts, range(5, 0, -1), range(1, 6)): \n",
    "#         if cnt == 0:\n",
    "#             continue\n",
    "                \n",
    "#         loop = min(math.ceil(cnt/20), 5)\n",
    "        \n",
    "#         noloop1 = noloop2 = False\n",
    "#         if cnt <= 100: noloop1 = True\n",
    "#         if cnt <= 200: noloop2 = True\n",
    "            \n",
    "#         for idx, fn2 in enumerate(['create_date_asc','create_date_desc','like_desc','like_asc']):\n",
    "#             url = uf.format(pn, fn1, fn2)\n",
    "#             driver.get(url)\n",
    "#             sleep(0.5)\n",
    "            \n",
    "#             # 앱으로보기 링크 있을경우 끄기\n",
    "#             banners = driver.find_elements_by_xpath('//*[@id=\"top-downloadbanner\"]/button')\n",
    "#             if len(banners)>0:\n",
    "#                 banners[0].click()\n",
    "                \n",
    "#             st = time()\n",
    "#             # 리뷰 리스트가 없으면 찾을때까지 대기\n",
    "#             while(True):\n",
    "#                 rlist = driver.find_elements_by_class_name('review-list-wrap')\n",
    "#                 if len(rlist)>0:\n",
    "#                     if (rlist[0].text != ''):\n",
    "#                         body = driver.find_element_by_css_selector('body')\n",
    "#                         body.click()\n",
    "#                         break\n",
    "#                 else:\n",
    "#                     driver.get(url)\n",
    "#                     sleep(0.5)\n",
    "                \n",
    "#                 if time() - st > 30:\n",
    "#                     errors.append([pn, fn1, fn2])\n",
    "#                     break\n",
    "                    \n",
    "             \n",
    "#             # 리뷰 개수가 일치해야 크롤링 시작\n",
    "#             st = time()\n",
    "#             while(True):\n",
    "#                 ctxt = driver.find_element_by_css_selector(count.format(cidx)).text\n",
    "#                 ctxt = int(ctxt)\n",
    "#                 if cnt == ctxt:\n",
    "#                     break\n",
    "#                 else: \n",
    "#                     driver.get(url)\n",
    "#                     sleep(0.5)\n",
    "                \n",
    "#                 if time() - st > 30:\n",
    "#                     errors.append([pn, fn1, fn2])\n",
    "#                     break\n",
    "                    \n",
    "            \n",
    "#             # 최대 100개, 스크롤 해야 로드하기 때문에 end키 조작으로 리뷰 불러오기\n",
    "#             st = time()\n",
    "#             while(True):\n",
    "#                 try:\n",
    "#                     body.send_keys(Keys.END) \n",
    "#                     reviews = driver.find_elements_by_css_selector('ul.review-list-wrap li div.list-item') \n",
    "\n",
    "#                     if time() - st > 3:\n",
    "#                         body.send_keys(Keys.PAGE_UP)\n",
    "#                         sleep(0.1) \n",
    "#                         body.send_keys(Keys.END)\n",
    "#                         st = time()\n",
    "\n",
    "#                     if len(reviews) > (loop-1) * 20:\n",
    "#                         break\n",
    "                \n",
    "#                 except Exception as e:\n",
    "#                     body = driver.find_element_by_css_selector('body')\n",
    "#                     body.click()\n",
    "                 \n",
    "                \n",
    "#             #print(len(reviews))\n",
    "#             # 리뷰 크롤링\n",
    "#             # beautifulsoup이 좀더 빠르다\n",
    "#             for r in reviews:\n",
    "#                 soup = BeautifulSoup(r.get_attribute('innerHTML'), 'lxml')\n",
    "#                 user = soup.select_one('.user .user-info')\n",
    "#                 name = user.select_one('.name').text\n",
    "#                 agetype = user.select_one('.info .txt')\n",
    "#                 arr = agetype.text.split('·')\n",
    "#                 age = int(arr[0].replace('세',''))\n",
    "#                 ftype = arr[1] \n",
    "#                 sex = agetype.select_one('span')['class']\n",
    "#                 point = user.select_one('.info .label span')['class'][1]\n",
    "#                 point = pdic[point]\n",
    "\n",
    "#                 comment = soup.select_one('.review').text\n",
    "\n",
    "#                 cr = review(pn, name, age, ftype, sex, point, comment)\n",
    "#                 creviews.append(cr)\n",
    "            \n",
    "#             if noloop1: break \n",
    "#             if noloop2 & (idx >= 1):break\n",
    "\n",
    "#     #rank = driver.find_element_by_css_selector('#gp-product-detail > div > ul.section-list-wrap.side-top > li.section-list-img.side-left > div > section > ul > li > span').text\n",
    "#     #print(rank) \n",
    "    \n",
    "#     ing = crawl_ingredient(pn)\n",
    "    \n",
    "#     return exp, tag, creviews, ing, errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
